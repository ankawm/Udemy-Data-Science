{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankawm/Udemy-Data-Science/blob/main/Kodolamacz_Spark_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7H1BELLCETf"
      },
      "source": [
        "# APACHE SPARK\n",
        "\n",
        "\n",
        "<div style=\"text-align: right\">\n",
        "<b>Patryk Pilarski</b><br>\n",
        "1patryk.pilarski@gmail.com<br>\n",
        "p.pilarski@sages.com.pl\n",
        "</div>\n",
        "\n",
        "\n",
        "### Dzień 1\n",
        "\n",
        "#### Wprowadzenie + Spark SQL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgw2Fme8CFNb",
        "outputId": "bf2afc35-95fd-4855-cccf-f3e0bc3cb126"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 48.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=508e205205835185c42dd1d08f218ab8b17e9cd772d0db66b5e0f5574def57bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV6wqNtbCETu"
      },
      "source": [
        "Apache Spark to silnik do obliczeń rozproszonych na licencji open-source. Pierwotnie powstał na Berkley, po czym przekazano go do Apache Software Foundation gdzie jest od tamtej pory utrzymywany i rozwijany. Spark oferuje interfejs pozwalający na programowanie obliczeń na klastrach z domyślną paralelizacją oraz odpornością na awarie.\n",
        "\n",
        "Spark dostępny jest w Scali, Pythonie, Javie oraz R.\n",
        "\n",
        "**Komponenty Sparka:**\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "* Spark \"core\" - podstawa Sparka z podstawową abstrakcją danych nazywaną RDD\n",
        "* Spark SQL - komponent pozwalający na operowanie na ustrukturyzowanych danych z wykorzystaniem operacji znanych z SQL - łatwy w użyciu\n",
        "* Spark MLlib - komponent zawierający algorytmy ML dostępne w Sparku - ML na skalę klastrów\n",
        "* Spark Streaming - moduł pozwalający na pracę ze strumnieniami danych\n",
        "* Spark GraphX - komponent do pracy z grafami\n",
        "\n",
        "**Architektura Sparka:**\n",
        "\n",
        "![image-2.png](attachment:image-2.png)\n",
        "\n",
        "* driver - proces uruchamiający główną funkcję aplikacji i tworzący SparkContext\n",
        "* executor(y) - proces uruchomiony dla aplikacji w węźle roboczym (worker node), który uruchamia zadania i przechowuje dane w pamięci lub na dysku. Każda aplikacja ma własne executory\n",
        "* cluster manager - dostępne opcje: YARN, Mesos, Kubernetes, Standalone\n",
        "\n",
        "**SparkContext:**\n",
        "* punkt wejścia do pracy ze Sparkiem\n",
        "* koordynuje procesy na klastrze\n",
        "* zatrzymanie SparkContextu == zatrzymanie działania aplikacji\n",
        "* zwykle nazywany `sc`\n",
        "* kroki niezbędne do utworzenia SparkContextu w pySparku:\n",
        "\n",
        "> import pyspark\n",
        "\n",
        "> sc = pyspark.SparkContext(appName=\"my_app\")\n",
        "\n",
        "**SparkSession:**\n",
        "* wprowadzony w Spark 2.0\n",
        "* składa się ze SparkContextu, SQLContextu oraz HiveContext\n",
        "* zwykle nazywany `spark`\n",
        "* kroki niezbędne do utworzenia SparkSession w pySparku:\n",
        "\n",
        "> from pyspark.sql import SparkSession\n",
        "\n",
        "> spark = SparkSession.builder.appName('my_app').getOrCreate()\n",
        "\n",
        "\n",
        "**RDD:**\n",
        "* podstawowa abstrakcja danych w Sparku\n",
        "* R - resilient\n",
        "* D - distributed\n",
        "* D - dataset\n",
        "* Matei Zharia, et al. `Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing`\n",
        "* immutable\n",
        "* in-memory\n",
        "* lazy evaluated\n",
        "* parallel\n",
        "* dwa typy operacji: akcje i transformacje\n",
        "* przykłady użycia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U61Xayp6CETx"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "sc = pyspark.SparkContext(appName=\"my_app\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCcA2Nq7CET1",
        "outputId": "5f038b4c-0ee4-4629-c531-2f64e44b2485"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "378"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "sc.parallelize(range(20))\\\n",
        ".map(lambda x: x * 2) \\\n",
        ".filter(lambda x: x != 2) \\\n",
        ".reduce(lambda x,y: x + y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QK0nAoYCET3",
        "outputId": "3a7945aa-3167-4280-8844-362858c63c90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('is', 2),\n",
              " ('engine', 1),\n",
              " ('compatible', 1),\n",
              " ('hadoop', 3),\n",
              " ('\\nit', 1),\n",
              " ('run', 1),\n",
              " ('in', 2),\n",
              " ('clusters', 1),\n",
              " ('yarn', 1),\n",
              " (\"spark's\", 1),\n",
              " ('mode', 1),\n",
              " ('process', 1),\n",
              " ('hdfs', 1),\n",
              " ('\\nhbase', 1),\n",
              " ('cassandra', 1),\n",
              " ('hive', 1),\n",
              " ('designed', 1),\n",
              " ('perform', 1),\n",
              " ('both', 1),\n",
              " ('\\n(similar', 1),\n",
              " ('new', 1),\n",
              " ('like', 1),\n",
              " ('streaming', 1),\n",
              " ('machine', 1),\n",
              " ('learning', 1),\n",
              " ('spark', 1),\n",
              " ('a', 1),\n",
              " ('fast', 1),\n",
              " ('and', 5),\n",
              " ('general', 1),\n",
              " ('processing', 2),\n",
              " ('with', 1),\n",
              " ('data', 2),\n",
              " ('can', 2),\n",
              " ('through', 1),\n",
              " ('or', 1),\n",
              " ('standalone', 1),\n",
              " ('it', 2),\n",
              " ('any', 1),\n",
              " ('inputformat', 1),\n",
              " ('to', 2),\n",
              " ('batch', 1),\n",
              " ('mapreduce', 1),\n",
              " ('workloads', 1),\n",
              " ('interactive', 1),\n",
              " ('queries', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "text_input = \"\"\"Spark is a fast and general processing engine compatible with Hadoop data. \n",
        "It can run in Hadoop clusters through YARN or Spark's standalone mode, and it can process data in HDFS, \n",
        "HBase, Cassandra, Hive, and any Hadoop InputFormat. It is designed to perform both batch processing \n",
        "(similar to MapReduce) and new workloads like streaming, interactive queries, and machine learning.\"\"\"\n",
        "\n",
        "sc.parallelize(text_input.split(\" \")) \\\n",
        ".map(lambda x: x.lower().strip(\",.()\")) \\\n",
        ".map(lambda x: (x, 1)) \\\n",
        ".reduceByKey(lambda x,y: x + y) \\\n",
        ".collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AeyLFnWbCET4"
      },
      "outputs": [],
      "source": [
        "sc.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dokumentacja dot. RDD:\n",
        "\n",
        "https://spark.apache.org/docs/latest/api/python/reference/pyspark.html"
      ],
      "metadata": {
        "id": "gvczuNaMT0rW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFJwFt_FCET6"
      },
      "source": [
        "**DataFrame:**\n",
        "* abstrakcja danych z modułu Spark SQL - u podstaw leżą RDD\n",
        "* immutable\n",
        "* in-memory\n",
        "* resilient\n",
        "* distributed\n",
        "* parallel\n",
        "* przechowuje dodatkowe informacje o strukturze danych (schema)\n",
        "* rozproszona kolekcja wierszy z nazwanymi kolumnami\n",
        "* optymalizowane przez Catalyst Optymizer\n",
        "* pozwala na pracę z danymi wykorzysując zapytania znane z SQL/Hive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JkKI66RICET_"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import functions as f\n",
        "\n",
        "spark = SparkSession.builder.appName('my_app').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "V5_okkeDCEUA",
        "outputId": "f222f51e-1974-4252-9891-feae29c18366"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://427733747b86:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>my_app</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fce74dfa1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hlJQgqkCEUB"
      },
      "source": [
        "**DataFrame - kolekcja wierszy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jqkX8X-4CEUD"
      },
      "outputs": [],
      "source": [
        "dummy_df = spark.createDataFrame([Row(name='Greg', age=32),\n",
        "                                  Row(name='Bob', age=27),\n",
        "                                  Row(name='Alice', age=30)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC0P7ZCXCEUE",
        "outputId": "b77fd2df-af43-4854-88a8-c34ce37b72a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "| Greg| 32|\n",
            "|  Bob| 27|\n",
            "|Alice| 30|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gwlD3LhyCEUF"
      },
      "outputs": [],
      "source": [
        "dummy_df2 = spark.createDataFrame([Row(name='Bill', age=26),\n",
        "                                   Row(name='Carol', age=28),\n",
        "                                   Row(name='Susan', age=25), \n",
        "                                   Row(name='Mark', age=None)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGxguBFpCEUG",
        "outputId": "3f87235b-c07c-4eb8-d911-2171fdb7819f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+\n",
            "| name| age|\n",
            "+-----+----+\n",
            "| Bill|  26|\n",
            "|Carol|  28|\n",
            "|Susan|  25|\n",
            "| Mark|null|\n",
            "+-----+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_df2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTgDtE96CEUH",
        "outputId": "783c9b44-3c4c-411d-875a-04e739ae9326"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(name='Greg', age=32), Row(name='Bob', age=27), Row(name='Alice', age=30)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "dummy_df.take(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_df2.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAGqeFu1aFmi",
        "outputId": "6c33aa14-2860-4240-c3d8-344c352305df"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(name='Bill', age=26),\n",
              " Row(name='Carol', age=28),\n",
              " Row(name='Susan', age=25),\n",
              " Row(name='Mark', age=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4TduFXlCEUI"
      },
      "source": [
        "**DataFrame - właściwości**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HL9bnilCEUI",
        "outputId": "c9a0d458-f207-4f6a-dfb9-bbdc2fc87d31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['name', 'age']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "dummy_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XtNv-zyCEUJ",
        "outputId": "a88c73aa-ca4d-4fc9-8bcc-0f7e236044e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('name', 'string'), ('age', 'bigint')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dummy_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T6cEkWDCEUJ",
        "outputId": "98b53c6c-ca96-4bee-cb25-b199d330657d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQFa4SkMCEUK",
        "outputId": "2da51be9-1c93-47ae-a7af-e2be5b6c31cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+------------------+\n",
            "|summary| name|               age|\n",
            "+-------+-----+------------------+\n",
            "|  count|    3|                 3|\n",
            "|   mean| null|29.666666666666668|\n",
            "| stddev| null|2.5166114784235836|\n",
            "|    min|Alice|                27|\n",
            "|    max| Greg|                32|\n",
            "+-------+-----+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_df.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldA3Gw4mCEUM",
        "outputId": "f1e4a658-5478-4c46-9120-248cc6887023"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "dummy_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dummy_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxn-D804bBkk",
        "outputId": "759f4448-2779-4d71-f6f7-64c3c23ced07"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H71OwUfCEUM"
      },
      "source": [
        "**Sposoby odwoływania się do kolumn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vwD55oICEUM",
        "outputId": "f2631e46-ee8c-406a-a352-7f490a791a9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'age'>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "dummy_df.age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbquHTkFCEUO",
        "outputId": "1dd9f0be-05f0-4848-80d8-667d8c5dd71c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'age'>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "dummy_df[\"age\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_55no9ccCEUP",
        "outputId": "596ab1b3-9842-4527-ea43-394faa931015"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'age'>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "dummy_df[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLkx3eVTCEUP",
        "outputId": "9f83209d-6200-498d-d72f-11e0438d054a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'age'>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "f.col(\"age\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4vj3ZaA7CEUP",
        "outputId": "241da062-296d-403c-86b1-9295ef68ae38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'age'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "\"age\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac84FYP6CEUQ"
      },
      "source": [
        "**Składnia inspirowana SQL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90tdn_urCEUQ",
        "outputId": "6fcf75fc-3648-4a6b-ee66-252dba1d285a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|age|\n",
            "+---+\n",
            "| 32|\n",
            "| 27|\n",
            "| 30|\n",
            "+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_df.select(\"age\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q33CitO9CEUR",
        "outputId": "064806ce-f029-405c-d442-030843a2becc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "| Greg| 32|\n",
            "|Alice| 30|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_df.where(dummy_df[\"age\"] > 27).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHwpq5haCEUR",
        "outputId": "668d9045-6c69-461c-c58b-9d6527db9049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|          avg(age)|\n",
            "+------------------+\n",
            "|29.666666666666668|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_df.agg(f.avg(dummy_df[\"age\"])).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu8xfyZFCEUR",
        "outputId": "b6d0c73e-4827-40aa-f4df-fa560ede5da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|          avg(age)|\n",
            "+------------------+\n",
            "|29.666666666666668|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# lub bardziej SQLowo\n",
        "dummy_df.select(f.avg(dummy_df[\"age\"])).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usAuYsnGCEUS",
        "outputId": "7a6d4161-d0f7-4ed3-94fe-87d5efdc07dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|          avg(age)|\n",
            "+------------------+\n",
            "|29.666666666666668|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_df.selectExpr(\"avg(age)\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXrjtgi7CEUT",
        "outputId": "0c91897d-f456-485a-8431-ae29809a784f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+\n",
            "| name| age|\n",
            "+-----+----+\n",
            "| Greg|  32|\n",
            "|  Bob|  27|\n",
            "|Alice|  30|\n",
            "| Bill|  26|\n",
            "|Carol|  28|\n",
            "|Susan|  25|\n",
            "| Mark|null|\n",
            "+-----+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_df.union(dummy_df2).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drCdwguCCEUT"
      },
      "source": [
        "**Zapisywanie wyników**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "L1BtZSHRCEUT"
      },
      "outputs": [],
      "source": [
        "#dummy_df.write.parquet('path/to/location/dummy_df.parquet')\n",
        "#dummy_df.write.csv('path/to/location/dummy_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OFSDz5aYCEUU"
      },
      "outputs": [],
      "source": [
        "dummy_df.write.parquet(\"p\", mode=\"overwrite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "g-1JqHScCEUU"
      },
      "outputs": [],
      "source": [
        "dummy_df.repartition(1).write.csv('csv', mode=\"overwrite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "HWcVPRdBCEUU",
        "outputId": "af0f8d43-6f40-4fde-a8ff-0a04ed03b06f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b0f63616-0ef0-4344-8ae3-05aafc87c703\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Greg</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bob</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Alice</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0f63616-0ef0-4344-8ae3-05aafc87c703')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0f63616-0ef0-4344-8ae3-05aafc87c703 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0f63616-0ef0-4344-8ae3-05aafc87c703');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    name  age\n",
              "0   Greg   32\n",
              "1    Bob   27\n",
              "2  Alice   30"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "dummy_df.toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mcfAb5PCEUV"
      },
      "source": [
        "**Wczytywanie danych**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NaTah5NCEUV"
      },
      "outputs": [],
      "source": [
        "#parquet_df = spark.read.parquet('path/to/parquet')\n",
        "#csv_df = spark.read.csv('path/to/csv', header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I28m7aBnCEUV"
      },
      "outputs": [],
      "source": [
        "spark.read.parquet(\"p\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzR4CX29CEUV"
      },
      "outputs": [],
      "source": [
        "spark.read.parquet(\"p\").explain()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCOSyYWECEUW"
      },
      "outputs": [],
      "source": [
        "spark.read.parquet(\"p\").select(\"age\").explain()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVpFTnL-CEUW"
      },
      "source": [
        "**Używanie zapytań SQLowych**\n",
        "\n",
        "https://spark.apache.org/docs/latest/sql-programming-guide.html#compatibility-with-apache-hive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cWn3i9vCEUX"
      },
      "outputs": [],
      "source": [
        "dummy_df.createOrReplaceTempView('dummy_df')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d5OrwhRCEUY"
      },
      "outputs": [],
      "source": [
        "# query zwraca nowy DataFrame\n",
        "spark.sql('select * from dummy_df').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj0pwhixCEUY"
      },
      "outputs": [],
      "source": [
        "spark.sql('select name from dummy_df where age > 27').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svgi3BbSCEUY"
      },
      "outputs": [],
      "source": [
        "spark.catalog.dropTempView(\"dummy_df\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWO9910YCEUZ"
      },
      "source": [
        "### Przykładowe transformacje z wykorzystaniem API Spark SQL oraz selectów SQLowych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh6E6ZsfCEUZ"
      },
      "source": [
        "**Tworzenie pokazowych DataFrameów**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8v1R_0ICEUZ"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKiJIRiwCEUZ"
      },
      "outputs": [],
      "source": [
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-CTDGdzCEUZ"
      },
      "outputs": [],
      "source": [
        "geo_id = [random.choice([\"regA\",\"regB\",\"regC\",\"regD\",\"regE\",\"regF\"]) for x in range(400)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0NfukwQCEUa"
      },
      "outputs": [],
      "source": [
        "prod_id = [random.choice([\"prodA\",\"prodB\",\"prodC\",\"prodD\",\"prodE\",\"prodF\",\n",
        "                          \"prodG\",\"prodH\",\"prodI\",\"prodJ\",\"prodK\",\"prodL\",\"prodM\"]) for x in range(400)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By0MsAWdCEUc"
      },
      "outputs": [],
      "source": [
        "value = [random.uniform(1000,10000) for x in range(400)]\n",
        "value[10] = None\n",
        "value[17] = None\n",
        "value[123] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gz5czczCEUd"
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame([Row(prod=p, geo=g, val=v) for p,g,v in zip(prod_id, geo_id, value)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz39ucatCEUf"
      },
      "outputs": [],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YIHrCK2CEUg"
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView('train_df')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_cc5RFECEUg"
      },
      "outputs": [],
      "source": [
        "geo_df = spark.createDataFrame([Row(geo_id = \"regA\", geo_name = \"Region A\"),\n",
        "                                Row(geo_id = \"regB\", geo_name = \"Region B\"),\n",
        "                                Row(geo_id = \"regC\", geo_name = \"Region C\"),\n",
        "                                Row(geo_id = \"regD\", geo_name = \"Region D\"),\n",
        "                                Row(geo_id = \"regE\", geo_name = \"Region_E\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onEx9D8eCEUh"
      },
      "outputs": [],
      "source": [
        "geo_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF_Z9gS5CEUh"
      },
      "outputs": [],
      "source": [
        "geo_df.createOrReplaceTempView(\"geo_df\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThAXATBfCEUj"
      },
      "source": [
        "**Select**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFnQSf7PCEUk"
      },
      "outputs": [],
      "source": [
        "df.select(\"prod\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVerDTkACEUl"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select prod from train_df\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxIqpe8ICEUm"
      },
      "outputs": [],
      "source": [
        "df.drop(\"prod\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-I79uajCCEUn"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select geo, val from train_df\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t744LV2mCEUn"
      },
      "outputs": [],
      "source": [
        "df.select((df[\"val\"]* 2).alias(\"val2\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEobrA4HCEUo"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select val * 2 as val2 from train_df\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOg80yqTCEUo"
      },
      "outputs": [],
      "source": [
        "df.selectExpr(\"val * 2 val2\", \"val\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOLnPq37CEUp"
      },
      "source": [
        "**Group by**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20wIBT5tCEUp"
      },
      "outputs": [],
      "source": [
        "df.groupBy(\"prod\").sum().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r5wa0iwCEUq"
      },
      "outputs": [],
      "source": [
        "df.select(\"*\", df.val.alias(\"val2\")).groupBy(\"prod\").sum().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03zfAJshCEUr"
      },
      "outputs": [],
      "source": [
        "df.select(\"*\", df.val.alias(\"val2\")).groupBy(\"prod\").sum(\"val2\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RkcdhVPCEUt"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select prod, sum(val) from train_df group by prod\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYpZkI1WCEUw"
      },
      "outputs": [],
      "source": [
        "df.groupBy(\"prod\",\"geo\").sum().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeFRTa8xCEUy"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select prod, geo, sum(val) from train_df group by 1, 2\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ZgDl6kCEUz"
      },
      "source": [
        "**Where (filter)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-nBLEDSCEUz"
      },
      "outputs": [],
      "source": [
        "df.where(df[\"prod\"] != \"prodA\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PA42AMTuCEUz"
      },
      "outputs": [],
      "source": [
        "df.where(df[\"prod\"] != \"prodA\").where(f.col(\"val\") > 7000).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXrXFqMbCEU0"
      },
      "outputs": [],
      "source": [
        "df.where((df[\"prod\"] != \"prodA\") | (f.col(\"val\") > 7000)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yemu2AlTCEU0"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select * from train_df where prod != 'prodA'\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEa34wCeCEU1"
      },
      "outputs": [],
      "source": [
        "df.where(\"prod != 'prodA'\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgRoPpY4CEU1"
      },
      "outputs": [],
      "source": [
        "# like\n",
        "df.where(df.prod.like('%A')).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoQ2dim2CEU2"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select * from train_df where prod like '%A'\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gekQ-zNbCEU2"
      },
      "source": [
        "> **ZADANIE**:   \n",
        ">(punkty rozwiąż na dwa sposoby)\n",
        "1. Oblicz średnią wartość dla produktów A i B w regionach C i D\n",
        "2. Oblicz maksymalne wartości dla produktu A w podziale na regiony"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWY7F7nlCEU2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDV_YCfqCEU3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnEWv_3pCEU3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvyEhim6CEU3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx-P8opgCEU4"
      },
      "source": [
        "**Order by**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYcTTyhgCEU5"
      },
      "outputs": [],
      "source": [
        "df.groupBy(\"prod\",\"geo\").sum().orderBy(\"geo\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDqyr1vACEU5"
      },
      "outputs": [],
      "source": [
        "df.groupBy(\"prod\",\"geo\").sum().orderBy(f.desc(\"geo\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhS0nucOCEU6"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select prod, geo, sum(val) from train_df group by 1, 2 order by 2\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9e-XeH9CEU6"
      },
      "source": [
        "**Wiele agregacji + aliasy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AMSCE47CEU6"
      },
      "outputs": [],
      "source": [
        "df.groupBy(\"prod\",\"geo\").agg(f.sum(\"val\").alias(\"val_sum\"), f.avg(\"val\").alias(\"val_avg\"), \n",
        "                             f.count(\"*\"), f.count(\"val\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKbQyASnCEU7"
      },
      "outputs": [],
      "source": [
        "q = (\"select prod, geo, sum(val) val_sum, avg(val) val_avg, count(*), count(val) \" \n",
        "     \"from train_df group by prod, geo\")\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K8E6ZGzCEU7"
      },
      "source": [
        "> **ZADANIE**:   \n",
        ">(rozwiąż na dwa sposoby)\n",
        "1. Oblicz różnicę pomiędzy maksymalną i minimalną wartością dla poszczególnych produktów w regionie F, wynik posortuj po nazwach produktów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6by35S9KCEU8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWkS9u5vCEU9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9xIY2U9CEU9"
      },
      "source": [
        "**Joiny**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vro7nxjDCEU-"
      },
      "outputs": [],
      "source": [
        "# dostępne: inner, cross, outer, full, full_outer, left, left_outer, right, right_outer, left_semi, i left_anti\n",
        "df.join(geo_df, df.geo == geo_df.geo_id, \"inner\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47op3QnuCEU-"
      },
      "outputs": [],
      "source": [
        "df.join(geo_df, df.geo == geo_df.geo_id, \"inner\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcPqDkuBCEU-"
      },
      "outputs": [],
      "source": [
        "q = \"\"\"select train_df.prod, train_df.geo, train_df.val, geo_df.geo_name \n",
        "from train_df inner join geo_df on train_df.geo == geo_df.geo_id\"\"\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tVXb2hsCEU-"
      },
      "outputs": [],
      "source": [
        "df.join(geo_df, df.geo == geo_df.geo_id, \"outer\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuoyaj9ZCEU-"
      },
      "outputs": [],
      "source": [
        "df.join(geo_df, df.geo == geo_df.geo_id, \"outer\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osRf7nlzCEU_"
      },
      "outputs": [],
      "source": [
        "q = \"\"\"select train_df.prod, train_df.geo, train_df.val, geo_df.geo_name \n",
        "from train_df full outer join geo_df on train_df.geo == geo_df.geo_id\"\"\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JUdHjDdCEU_"
      },
      "outputs": [],
      "source": [
        "q = \"\"\"select train_df.prod, train_df.geo, train_df.val, geo_df.geo_name \n",
        "from train_df full outer join geo_df on train_df.geo == geo_df.geo_id\"\"\"\n",
        "spark.sql(q).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH2iRlcmCEU_"
      },
      "outputs": [],
      "source": [
        "df_tmp = df.withColumnRenamed(\"geo\", \"geo_id\")\n",
        "df_tmp.join(geo_df, \"geo_id\", \"inner\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PG20ejGVCEU_"
      },
      "outputs": [],
      "source": [
        "# tak nie robić!\n",
        "df_tmp.join(geo_df, df_tmp.geo_id == geo_df.geo_id, \"inner\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__fmfNiMCEVA"
      },
      "source": [
        "**Distinct**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUPt_ePYCEVA"
      },
      "outputs": [],
      "source": [
        "df.select(\"prod\", \"geo\").distinct().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq0RIcl-CEVA"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select distinct prod, geo from train_df\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ur2jWktCEVA"
      },
      "outputs": [],
      "source": [
        "# alternatywnie\n",
        "df.dropDuplicates([\"prod\", \"geo\"]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpmU9zNaCEVA"
      },
      "source": [
        "**Usuwanie NULLi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKCuBz3bCEVB"
      },
      "outputs": [],
      "source": [
        "# \"any\" or \"all\"\n",
        "df.dropna(\"any\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8o-nxM-CEVB"
      },
      "outputs": [],
      "source": [
        "df.dropna(\"any\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxQ3Id00CEVB"
      },
      "outputs": [],
      "source": [
        "q = \"select * from train_df where val is not null\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqgBNVKPCEVC"
      },
      "outputs": [],
      "source": [
        "q = \"select * from train_df where val is not null\"\n",
        "spark.sql(q).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjN4H0XaCEVC"
      },
      "outputs": [],
      "source": [
        "df.where(df.val.isNull()).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfNhxLErCEVD"
      },
      "outputs": [],
      "source": [
        "df.where(f.isnull(\"val\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBrNt-FrCEVD"
      },
      "source": [
        "**Zastępowanie NULLi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIJIP59FCEVD"
      },
      "outputs": [],
      "source": [
        "df.fillna(1).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHJOiTWGCEVE"
      },
      "outputs": [],
      "source": [
        "df.fillna({\"val\": 1}).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bfd9e7toCEVE"
      },
      "outputs": [],
      "source": [
        "q = \"select prod, geo, if(val is null, 1, val) as val from train_df\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "550A5JGGCEVF"
      },
      "source": [
        "**Podmiana wartości**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBM21fMVCEVF"
      },
      "outputs": [],
      "source": [
        "df.replace(\"prodA\", \"Product A\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMJsEb5ICEVG"
      },
      "outputs": [],
      "source": [
        "df.replace({\"prodA\": \"Product A\", \"prodB\": \"Product B\"}).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhVFDUxxCEVG"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select geo, regexp_replace(prod, 'prodA', 'Product A') as prod, val from train_df\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eilea8jfCEVH"
      },
      "source": [
        "> **ZADANIE**:   \n",
        ">(rozwiąż na dwa sposoby)\n",
        "1. W dowolny sposób przygotuj df w którym kolumny geo i prod zawierają jedynie litery identyfikujące produkty i regiony"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clEDEaurCEVI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlxF8IAUCEVJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A-F2auRCEVJ"
      },
      "source": [
        "**Zmiana nazw kolumn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SvCikWrCEVJ"
      },
      "outputs": [],
      "source": [
        "df.withColumnRenamed(\"val\", \"volume\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKV7DM2ECEVK"
      },
      "outputs": [],
      "source": [
        "df.select(df.val.alias(\"volume\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-2fIi7JCEVK"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select prod, geo, val as volume from train_df\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgCKTABaCEVK"
      },
      "source": [
        "**Tworzenie nowej kolumny**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaYAArmYCEVL"
      },
      "outputs": [],
      "source": [
        "df.withColumn(\"val2\", df[\"val\"] / 100).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMDEbuFOCEVL"
      },
      "outputs": [],
      "source": [
        "df.withColumn(\"val2\", f.lit(100)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhxT3e5MCEVM"
      },
      "outputs": [],
      "source": [
        "df.select(\"*\", (df.val/100).alias(\"val2\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F7PYuQ4CEVM"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select *, val/100 as val2 from train_df\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4saOVwZPCEVN"
      },
      "source": [
        "**When**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEnxT_7bCEVQ"
      },
      "outputs": [],
      "source": [
        "df.select(df.prod, f.when(df.val > 7500, 1).when(df.val < 2500, 3).otherwise(2).alias(\"out\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk0WHKA8CEVR"
      },
      "outputs": [],
      "source": [
        "df.select(df.prod, df.val, f.when(df.val >= 7500, 1).when(df.val >= 2500, 2)\\\n",
        "          .when(df.val < 2500, 3).alias(\"out\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "_zcDafCVCEVS"
      },
      "outputs": [],
      "source": [
        "q = \"select prod, case when val > 7500 then 1 when val < 2500 then 3 else 2 end as out from train_df\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV8lDutICEVT"
      },
      "source": [
        "**Substring**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2zQISWmCEVT"
      },
      "outputs": [],
      "source": [
        "df.select(df.prod.substr(2, 4).alias(\"out\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgV-_H6cCEVU"
      },
      "outputs": [],
      "source": [
        "df.select(f.substring(\"prod\", 2, 4).alias(\"out\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp0YzmCjCEVU"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select substring(prod, 2, 4) as val2 from train_df\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE1yjjXxCEVU"
      },
      "source": [
        "**Funkcje analityczne (window functions)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZe6Y7xCCEVU"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.window import Window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_7zaBRECEVV"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy('prod')\n",
        "\n",
        "df.select(\"prod\", \"val\", f.sum(\"val\").over(windowSpec).alias(\"prod_val\")).show(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoUhKWUqCEVV"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select prod, val, sum(val) over (partition by prod) as prod_val from train_df\").show(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gxJwFveCEVV"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A3oEA_PCEVV"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjVZEChyCEVV"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "qEgd1jMnCEVW"
      },
      "source": [
        "### Ćwiczenia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92k8b6e7CEVW"
      },
      "source": [
        "**Importy i przygotowanie danych**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxvCXPNeCEVX"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql.window import Window\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2B0wmCytCEVX"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName('my_app').master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8YiPV71CEVY"
      },
      "source": [
        "https://www.fordgobike.com/system-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M60R5MUqCEVY"
      },
      "outputs": [],
      "source": [
        "goBike = spark.read.csv(\"./2017-fordgobike-tripdata.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GVh-U_TCEVZ"
      },
      "outputs": [],
      "source": [
        "goBike.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nct9OzYHCEVZ"
      },
      "outputs": [],
      "source": [
        "goBike.show(3, vertical=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFsjbrBXCEVa"
      },
      "source": [
        "> **ZADANIE 1**: Zapoznaj się z danymi:\n",
        "1. Pozbądź się wierszy zawierających NULLe\n",
        "1. Sprawdź rozkład zmiennej \"member_gender\"\n",
        "2. Oblicz minimalny, maksymalny i średni wiek osób wypożyczających rowery\n",
        "3. Oblicz liczbę unikalnych rowerów\n",
        "4. Oblicz liczbę unikalnych stacji\n",
        "5. Sprawdź który rower był wypożyczony najdłużej a który najkrócej w ciągu analizowanego okresu (oraz jak długo)\n",
        "6. Oblicz średni czas pojedynczego wypożyczenia\n",
        "7. Sprawdź pomiędzy którymi stacjami występował największy ruch (hint: A -> B == B -> A)\n",
        "8. Sprawdź o której godzinie w ciągu dnia wypożyczano najwięcej rowerów\n",
        "9. Sprawdź *średnią liczbę wypożyczeń* dla poszczególnych dni tygodnia (hint: java.text.SimpleDateFormat)\n",
        "10. **⋆** Oblicz średni dystans (w km) pomiędzy stacją początkową a końcową dla wszystkich wypożyczeń"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltRcBnEZCEVb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb1c8cA_CEVb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "letSXWFSCEVc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcLSr_rRCEVc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS7xAVnGCEVc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT8rW4z_CEVc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV_zIfnTCEVc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFeuxOVaCEVc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qvnL6xXCEVd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw6zaA_qCEVd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l7rqZIFCEVe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxkVgp1eCEVg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aTYJDn9CEVh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br0veYKtCEVj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPrBrBdaCEVj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGN3_jidCEVj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUgwEFSRCEVk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKDNxkOWCEVk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2FU0e4nCEVk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Teu4rIfGCEVk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEiF9mprCEVl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K_6vwuDCEVl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1aAIztYCEVl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_XrkiYuCEVl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm1X2NLUCEVl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5LmJS4gCEVm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tek_QZAXCEVm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozbdRYmOCEVm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-ooKkBgCEVm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJpWINrQCEVn"
      },
      "source": [
        "> **ZADANIE 2**: Utwórz DataFrame `dataDaily` zawierający dane zagregowane do poziomu dnia. Zbiór ma zawierać następujące informacje (kolumny): \n",
        "- 'date' : data \n",
        "- 'avg_duration_sec' : średni czas wypożyczeń danego dnia\n",
        "- 'n_trips' : liczba wypożyczeń danego dnia\n",
        "- 'n_bikes' : liczba unikatowych rowerów użytych danego dnia\n",
        "- 'n_routes' : liczba unikatowych kombinacji stacji (x -> y == y -> x) danego dnia\n",
        "- 'n_subscriber' : liczba wypożyczeń dokonanych przez subskrybentów danego dnia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s29Wf0LoCEVn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgO74afRCEVn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jezvent1CEVo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "WtJe6qlyCEVo"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "mHsxiUnBCEVq"
      },
      "source": [
        "**Przygotowanie danych**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgM3pk4zCEVr"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "geo_id = [random.choice([\"regA\",\"regB\",\"regC\",\"regD\",\"regE\",\"regF\"]) for x in range(400)]\n",
        "prod_id = [random.choice([\"prodA\",\"prodB\",\"prodC\",\"prodD\",\"prodE\",\"prodF\",\n",
        "                          \"prodG\",\"prodH\",\"prodI\",\"prodJ\",\"prodK\",\"prodL\",\"prodM\"]) for x in range(400)]\n",
        "date = [random.choice([\"2015-\",\"2016-\",\"2017-\"]) + \n",
        "        random.choice([\"01-\",\"02-\",\"03-\",\"04-\",\"05-\",\"06-\",\"07-\",\"08-\",\"09-\",\"10-\",\"11-\",\"12-\"]) + \"01\"\n",
        "        for x in range(400)]\n",
        "value = [random.uniform(10000,100000) for x in range(400)]\n",
        "volume = [random.uniform(1000,10000) for x in range(400)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GuZPRMhCEVr"
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame([Row(prod=p, geo=g, val=v, vol=vl, dt=d) \n",
        "                            for p,g,v,vl,d in zip(prod_id, geo_id, value, volume, date)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwDyE6fBCEVs"
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzKLyGVACEVt"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"dt\", f.to_date(df[\"dt\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXDdou_GCEVv"
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0N4iV7qCEVw"
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"df\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b5R2XbYCEVx"
      },
      "outputs": [],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd_VZcG3CEVy"
      },
      "source": [
        "> **ZADANIE 3:**\n",
        "1. Oblicz (globalną) średnią cenę produktów\n",
        "2. Oblicz wartość całkowitą dla regionów per miesiąc\n",
        "3. Oblicz udział wolumenu kombinacji region-produkt w całkowitym wolumenie produktu (jaka część całkowitego wolumenu danego produktu generowana jest w danym regionie)\n",
        "5. Stwórz kolumnę `flag` zwierającą wartość `True` gdy nazwy regionu i produktu kończą się na tą samą literę - wartość `False` w każdym innym przypadku (nadpisz df aby zawierał nową kolumnę)\n",
        "6. Oblicz iloczyn wartości i wolumenu gdy kolumna `flag` ma wartość `True`, w przeciwnym przypadku zwróć wartość 0 \n",
        "7. Stwórz kolumnę z rokiem wyciągniętym z daty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbu4xFsjCEVy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxZCTHJMCEVy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvW5fipkCEVy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmKwJbWGCEVz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTRyK-p2CEVz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asEFMXeyCEVz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS8Cws4LCEV0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCwlEP6-CEV0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmtODM22CEV0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zg-t2byXCEV1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-4SyeDeCEV1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wRpQNQhCEV1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2DQsOMkCEV1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy7v4AvLCEV3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa74iZ9zCEV4"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um6Rxv9rCEV4"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUUCLVWKCEV5"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "2ifEb41tCEV5"
      },
      "source": [
        "### Zaawansowane operacje na oknach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn2aMFlSCEV7"
      },
      "source": [
        "**Ranking**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTPIf1p8CEV9"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy(\"prod\").orderBy(\"dt\")\n",
        "\n",
        "df.withColumn(\"ranked\", f.rank().over(windowSpec))\\\n",
        ".withColumn(\"ranked_d\", f.dense_rank().over(windowSpec))\\\n",
        ".withColumn(\"row_num\", f.row_number().over(windowSpec)).show(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0HnB4X_CEV9"
      },
      "outputs": [],
      "source": [
        "q = \"select *, rank() over (partition by prod order by dt) as ranked from df\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIYG7n1NCEV-"
      },
      "source": [
        "**Różnica od pierwszej wartości**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jATzJDQxCEV_"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy(\"prod\").orderBy(\"dt\")\n",
        "\n",
        "df.withColumn(\"diff_from_first\", df.val - f.first(df.val).over(windowSpec)).show(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS8VGS1ACEV_"
      },
      "outputs": [],
      "source": [
        "q = \"select *, val - first(val) over (partition by prod order by dt) as diff_from_first from df\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uMSbqvICEV_"
      },
      "source": [
        "**Średnia ruchoma**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3snzXhgCEWA"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy(\"prod\").orderBy(\"dt\").rowsBetween(-1,1)\n",
        "\n",
        "df.withColumn(\"moving_avg\", f.avg(df.val).over(windowSpec)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwIPQbA7CEWA"
      },
      "outputs": [],
      "source": [
        "q = \"\"\"select *, \n",
        "avg(val) over (partition by prod order by dt rows between 1 preceding and 1 following) as moving_avg from df\"\"\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBKfzhRiCEWB"
      },
      "source": [
        "**Suma od pierwszego do bierzącego rekordu**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpZBszLxCEWC"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy(\"prod\").orderBy(\"dt\")\n",
        "\n",
        "df.withColumn(\"sum_from_start\", f.sum(df.val).over(windowSpec)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCt3lQmhCEWD"
      },
      "outputs": [],
      "source": [
        "q = \"select *, sum(val) over (partition by prod order by dt) as sum_from_start from df\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKzbAqVxCEWE"
      },
      "outputs": [],
      "source": [
        "# inne podejście\n",
        "windowSpec = Window.partitionBy(\"prod\").orderBy(\"dt\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
        "\n",
        "df.withColumn(\"sum_from_start\", f.sum(df.val).over(windowSpec)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86kD8KDyCEWE"
      },
      "outputs": [],
      "source": [
        "q = \"\"\"select *, sum(val) over (partition by prod order by dt rows between \n",
        "unbounded preceding and current row) as sum_from_start from df\"\"\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zi41DdYCEWG"
      },
      "source": [
        "> **ZADANIE 4:**\n",
        "1. Pogrupuj dane po dacie i produkcie po czym porównaj wolumen produktów ze średnim wolumenem z trzech wcześniejszych okresów\n",
        "2. Stwórz kolumnę z rankingiem opartm na dacie dla kombinacji produkt-region\n",
        "3. Oblicz różnicę w wolumenie pomiędzy następującymi po sobie datami dla regionów\n",
        "4. Oblicz różnicę rok do roku w wartości i wolumenie dla produktów\n",
        "5. Oblicz udział w całkowitej wartości poszczególnych produktów w danym roku dla każdego regionu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JtVMP7OCEWG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk-prpxXCEWH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K78mZddRCEWH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlYIH4pDCEWH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFo2GPyhCEWH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJsSB7PPCEWH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjR3FD6YCEWH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr9iJiFcCEWH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAA2hgUfCEWH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-4CLqAcCEWH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61wpKBTICEWI"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf3Qd5AeCEWI"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIiBs3MVCEWI"
      },
      "source": [
        "**Dodatek:**\n",
        "\n",
        "#### User Defined Functions (UDFs)\n",
        "\n",
        "(Używaj tylko w ostateczności)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1lPOQPICEWI"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import IntegerType, StringType, FloatType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyQl9QPvCEWI"
      },
      "outputs": [],
      "source": [
        "def udfPower3(value):\n",
        "    return value**3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_VXt8JICEWJ"
      },
      "outputs": [],
      "source": [
        "udfPower3(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-Rv-IY4CEWJ"
      },
      "outputs": [],
      "source": [
        "power3 = f.udf(udfPower3, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veHpWBfSCEWJ"
      },
      "outputs": [],
      "source": [
        "df.select(power3(df.val)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTVG-thcCEWJ"
      },
      "outputs": [],
      "source": [
        "spark.udf.register(\"power3\", udfPower3, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1Qle1ivCEWJ"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select power3(val) from df\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj_iziBmCEWJ"
      },
      "outputs": [],
      "source": [
        "def udfTwo_col(x,y):\n",
        "    return x / y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAuDNTsPCEWK"
      },
      "outputs": [],
      "source": [
        "udfTwo_col(10,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmAehFtkCEWL"
      },
      "outputs": [],
      "source": [
        "two_col = f.udf(udfTwo_col, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_N4cLSVJCEWM"
      },
      "outputs": [],
      "source": [
        "df.select(two_col(df.vol,df.val)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-cgRuevCEWM"
      },
      "outputs": [],
      "source": [
        "spark.udf.register(\"two_col\", udfTwo_col, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EvlamyqCEWM"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select two_col(vol,val) from df\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie2A1enWCEWM"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgd9u1WvCEWM"
      },
      "source": [
        "#### Pandas UDFs\n",
        "\n",
        "(lepsza alternatywa)\n",
        "\n",
        "https://spark.apache.org/docs/latest/sql-pyspark-pandas-with-arrow.html\n",
        "\n",
        "- wymagają zainstalowania pyarrow (`conda install -c conda-forge pyarrow` lub `pip install pyarrow`)\n",
        "- wymagają ustawienia parametru `spark.sql.execution.arrow.pyspark.enabled` na `true`\n",
        "- wymagają napisania funkcji które działają na seriach z biblioteki pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Da08qhsCEWN"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "from pyspark.sql.types import ArrayType, IntegerType\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ1QafQXCEWN"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName('app') \\\n",
        "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb1HRz_ACEWZ"
      },
      "outputs": [],
      "source": [
        "df_pd = spark.createDataFrame([(\"x\", \"one exemplary string\", 4, 4), \n",
        "                               (\"x\", \"and here too a string\", 3, 5), \n",
        "                               (\"y\", \"some more also here\", 5, 3), \n",
        "                               (\"y\", \"and another one\", 1, 7)], [\"f\", \"s\", \"a\", \"b\"])\n",
        "df_pd = df_pd.withColumn(\"s\", f.split(\"s\", \" \"))\n",
        "df_pd.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjvs6E7LCEWZ"
      },
      "source": [
        "----\n",
        "\n",
        "##### Funkcje działające na jednym wierszu\n",
        "- **pandas_udf(f, returnType)** - tworzy Pandas UDF zwracający kolumnę o wartościach typu `returnType`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-ezgpsFCEWa"
      },
      "outputs": [],
      "source": [
        "def array_elem_length(s: pd.Series) -> pd.Series:\n",
        "    return s.apply(lambda x: [len(y) for y in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH82yrLjCEWa"
      },
      "outputs": [],
      "source": [
        "s = pd.Series([[\"one\", \"exemplary\", \"string\"], [\"and\", \"here\", \"too\", \"a\", \"string\"]])\n",
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ebPEhWQCEWa"
      },
      "outputs": [],
      "source": [
        "array_elem_length(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTXJsH9xCEWb"
      },
      "outputs": [],
      "source": [
        "lenUDF = pandas_udf(array_elem_length, returnType=ArrayType(IntegerType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqjBAYmrCEWb"
      },
      "outputs": [],
      "source": [
        "df_pd.withColumn(\"s_len\", lenUDF(f.col(\"s\"))).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSWfcSwACEWb"
      },
      "outputs": [],
      "source": [
        "@pandas_udf(\"float\")\n",
        "def pythagoras(a: pd.Series, b: pd.Series) -> pd.Series:\n",
        "    return pd.concat([a, b], axis=1).apply(lambda x: np.sqrt(np.square(x[0]) + np.square(x[1])), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4th-4flQCEWb"
      },
      "outputs": [],
      "source": [
        "# a = pd.Series([4, 3, 5, 1])\n",
        "# b = pd.Series([4, 5, 3, 7])\n",
        "# pythagoras(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMaAh7faCEWc"
      },
      "outputs": [],
      "source": [
        "df_pd.withColumn(\"c\", pythagoras(df_pd.a, df_pd.b)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xcnh763CEWc"
      },
      "source": [
        "##### Funkcje agregujące"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mM2JzxJCEWd"
      },
      "outputs": [],
      "source": [
        "@pandas_udf(\"float\")\n",
        "def median(v: pd.Series) -> float:\n",
        "    return v.median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSfceRiUCEWd"
      },
      "outputs": [],
      "source": [
        "df_pd.groupby(\"f\").agg(median('a').alias(\"a_med\"), median('b').alias(\"b_med\")).show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Kodolamacz_Spark_1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eWO9910YCEUZ",
        "qEgd1jMnCEVW",
        "2ifEb41tCEV5",
        "SIiBs3MVCEWI",
        "hgd9u1WvCEWM"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}